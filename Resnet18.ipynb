{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "so3g52ujQdBe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.io import ImageReadMode\n",
        "from torchvision.io import read_image\n",
        "from torchvision.datasets import ImageFolder\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch \n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from torchvision import transforms as T\n",
        "import math\n",
        "from sklearn.metrics import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zqFgIV1WQjEZ",
        "outputId": "afc59bcd-cb1a-4865-d505-e0b92fec5bfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FHuHETCRDmP",
        "outputId": "8365e45b-8f2f-41ae-9480-2ee1eca3c8cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Recording  Label\n",
            "0        A4363      6\n",
            "1        A4447      4\n",
            "2        A0822      5\n",
            "3        A0415      2\n",
            "4        A5712      1\n",
            "...        ...    ...\n",
            "6184     A3728      5\n",
            "6185     A0683      1\n",
            "6186     A6561      5\n",
            "6187     A5674      2\n",
            "6188     A3270      3\n",
            "\n",
            "[6189 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv('train_image.csv')\n",
        "test = pd.read_csv('val_image.csv')\n",
        "print(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1ZC5kM9NRIus"
      },
      "outputs": [],
      "source": [
        "class ECGimage_DB(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir \n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0] +'.png')\n",
        "        image = read_image(img_path, mode=ImageReadMode.RGB)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image.float(), label-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XdeywH3ff41D"
      },
      "outputs": [],
      "source": [
        "class ECGimage_DBv(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir \n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0] +'.png')\n",
        "        image = read_image(img_path, mode=ImageReadMode.RGB)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image.float(), label-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ctMa4oXaRftA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/miniconda3/envs/IECG_class/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/miniconda3/envs/IECG_class/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 9)\n",
        "model = model.to(device)\n",
        "learning_rate = 1e-3\n",
        "epochs = 5\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=9, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "REkWHXoeTNqX"
      },
      "outputs": [],
      "source": [
        "path=\"ECGimg_ts\"\n",
        "train_db=ECGimage_DB('train_image.csv',path)\n",
        "valid_db= ECGimage_DBv('val_image.csv',path)\n",
        "\n",
        "train_dl=DataLoader(train_db, batch_size=16)\n",
        "valid_dl=DataLoader(valid_db, batch_size=16)\n",
        "# image = read_image(os.path.join(path,'A0001.png'),mode=ImageReadMode.RGB)\n",
        "\n",
        "# print(image.size())\n",
        "# flatten = nn.Flatten()\n",
        "# flat_image = flatten(image).float()\n",
        "# print(flat_image.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TeA8awe-WbNN"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader,0):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        # Backpropagation\n",
        "        pred = model(X)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u2PLYn_CWfgN"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "    running_y, running_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            pred1 = torch.argmax(pred,1)\n",
        "            labels = list(y.cpu().numpy())\n",
        "            \n",
        "            preds = list(pred1.cpu().numpy())\n",
        "            \n",
        "            running_y.extend(labels)\n",
        "            running_pred.extend(preds)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            # correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    f1 = f1_score(running_y,running_pred, average = 'macro')\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    # print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    print(f\"Test Error: \\n F1: {(f1):>0.1f}, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZmge5SXWjxJ",
        "outputId": "851ed083-07da-4b29-df8b-ee5a3ade14bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.414014  [    0/ 6189]\n",
            "loss: 1.856285  [ 1600/ 6189]\n",
            "loss: 1.743071  [ 3200/ 6189]\n",
            "loss: 1.969655  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.2, Avg loss: 1.635721 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.043333  [    0/ 6189]\n",
            "loss: 1.646938  [ 1600/ 6189]\n",
            "loss: 1.487276  [ 3200/ 6189]\n",
            "loss: 1.804085  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.3, Avg loss: 1.480400 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.855991  [    0/ 6189]\n",
            "loss: 1.455943  [ 1600/ 6189]\n",
            "loss: 1.207871  [ 3200/ 6189]\n",
            "loss: 1.563575  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 1.430946 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.719898  [    0/ 6189]\n",
            "loss: 1.309095  [ 1600/ 6189]\n",
            "loss: 1.218495  [ 3200/ 6189]\n",
            "loss: 1.629312  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 1.391986 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.639001  [    0/ 6189]\n",
            "loss: 1.313859  [ 1600/ 6189]\n",
            "loss: 1.138521  [ 3200/ 6189]\n",
            "loss: 1.432736  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 1.409015 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.585312  [    0/ 6189]\n",
            "loss: 0.839721  [ 1600/ 6189]\n",
            "loss: 0.973587  [ 3200/ 6189]\n",
            "loss: 1.149662  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 1.481343 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.290728  [    0/ 6189]\n",
            "loss: 0.717417  [ 1600/ 6189]\n",
            "loss: 0.986786  [ 3200/ 6189]\n",
            "loss: 1.157986  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 1.676346 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.211567  [    0/ 6189]\n",
            "loss: 0.622596  [ 1600/ 6189]\n",
            "loss: 1.043100  [ 3200/ 6189]\n",
            "loss: 1.320432  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 1.883829 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.879121  [    0/ 6189]\n",
            "loss: 0.432206  [ 1600/ 6189]\n",
            "loss: 0.480712  [ 3200/ 6189]\n",
            "loss: 0.597618  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 1.986473 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.906267  [    0/ 6189]\n",
            "loss: 0.281850  [ 1600/ 6189]\n",
            "loss: 0.577526  [ 3200/ 6189]\n",
            "loss: 0.503386  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 2.192575 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.845772  [    0/ 6189]\n",
            "loss: 0.305337  [ 1600/ 6189]\n",
            "loss: 1.292120  [ 3200/ 6189]\n",
            "loss: 0.317651  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 2.286363 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.275185  [    0/ 6189]\n",
            "loss: 0.364721  [ 1600/ 6189]\n",
            "loss: 0.852917  [ 3200/ 6189]\n",
            "loss: 0.652693  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.5, Avg loss: 2.332791 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.267431  [    0/ 6189]\n",
            "loss: 0.111081  [ 1600/ 6189]\n",
            "loss: 1.089851  [ 3200/ 6189]\n",
            "loss: 0.594133  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 2.419931 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.165957  [    0/ 6189]\n",
            "loss: 0.133440  [ 1600/ 6189]\n",
            "loss: 0.597940  [ 3200/ 6189]\n",
            "loss: 0.122612  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 2.532362 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.171653  [    0/ 6189]\n",
            "loss: 0.286566  [ 1600/ 6189]\n",
            "loss: 0.128985  [ 3200/ 6189]\n",
            "loss: 0.299526  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 2.723309 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.252536  [    0/ 6189]\n",
            "loss: 0.380399  [ 1600/ 6189]\n",
            "loss: 0.205121  [ 3200/ 6189]\n",
            "loss: 0.021356  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 2.821591 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.080175  [    0/ 6189]\n",
            "loss: 0.231052  [ 1600/ 6189]\n",
            "loss: 1.192367  [ 3200/ 6189]\n",
            "loss: 0.161027  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.098761 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.081029  [    0/ 6189]\n",
            "loss: 0.047721  [ 1600/ 6189]\n",
            "loss: 0.167100  [ 3200/ 6189]\n",
            "loss: 0.148656  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.085979 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.465358  [    0/ 6189]\n",
            "loss: 0.072396  [ 1600/ 6189]\n",
            "loss: 0.054100  [ 3200/ 6189]\n",
            "loss: 0.231373  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.5, Avg loss: 3.243318 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.018830  [    0/ 6189]\n",
            "loss: 0.083837  [ 1600/ 6189]\n",
            "loss: 0.101426  [ 3200/ 6189]\n",
            "loss: 0.317637  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.310913 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.080551  [    0/ 6189]\n",
            "loss: 0.181427  [ 1600/ 6189]\n",
            "loss: 1.197002  [ 3200/ 6189]\n",
            "loss: 0.072231  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.340130 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.220687  [    0/ 6189]\n",
            "loss: 0.152484  [ 1600/ 6189]\n",
            "loss: 0.284423  [ 3200/ 6189]\n",
            "loss: 0.023233  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.394549 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.107963  [    0/ 6189]\n",
            "loss: 0.105368  [ 1600/ 6189]\n",
            "loss: 0.071515  [ 3200/ 6189]\n",
            "loss: 0.006293  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.605259 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.016674  [    0/ 6189]\n",
            "loss: 0.028102  [ 1600/ 6189]\n",
            "loss: 0.075133  [ 3200/ 6189]\n",
            "loss: 0.153916  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.460701 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.025592  [    0/ 6189]\n",
            "loss: 0.301431  [ 1600/ 6189]\n",
            "loss: 1.594506  [ 3200/ 6189]\n",
            "loss: 0.041771  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.358431 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.285733  [    0/ 6189]\n",
            "loss: 0.037336  [ 1600/ 6189]\n",
            "loss: 0.188839  [ 3200/ 6189]\n",
            "loss: 0.026063  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.549414 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.361198  [    0/ 6189]\n",
            "loss: 0.111265  [ 1600/ 6189]\n",
            "loss: 0.155630  [ 3200/ 6189]\n",
            "loss: 0.022276  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.608297 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.025993  [    0/ 6189]\n",
            "loss: 0.017946  [ 1600/ 6189]\n",
            "loss: 0.086734  [ 3200/ 6189]\n",
            "loss: 0.166948  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.690168 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.045239  [    0/ 6189]\n",
            "loss: 0.025756  [ 1600/ 6189]\n",
            "loss: 0.013232  [ 3200/ 6189]\n",
            "loss: 0.052204  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.451361 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.009862  [    0/ 6189]\n",
            "loss: 0.044250  [ 1600/ 6189]\n",
            "loss: 0.084807  [ 3200/ 6189]\n",
            "loss: 0.029818  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.485009 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.006890  [    0/ 6189]\n",
            "loss: 0.055528  [ 1600/ 6189]\n",
            "loss: 0.868120  [ 3200/ 6189]\n",
            "loss: 0.076725  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.537833 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.079587  [    0/ 6189]\n",
            "loss: 0.072034  [ 1600/ 6189]\n",
            "loss: 0.083957  [ 3200/ 6189]\n",
            "loss: 0.058727  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.5, Avg loss: 3.560066 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.092464  [    0/ 6189]\n",
            "loss: 0.021153  [ 1600/ 6189]\n",
            "loss: 0.027264  [ 3200/ 6189]\n",
            "loss: 0.401789  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.569914 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.011620  [    0/ 6189]\n",
            "loss: 0.012389  [ 1600/ 6189]\n",
            "loss: 0.186480  [ 3200/ 6189]\n",
            "loss: 0.073191  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.569898 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.049470  [    0/ 6189]\n",
            "loss: 0.058907  [ 1600/ 6189]\n",
            "loss: 0.029957  [ 3200/ 6189]\n",
            "loss: 0.010276  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.5, Avg loss: 3.562651 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.012050  [    0/ 6189]\n",
            "loss: 0.159599  [ 1600/ 6189]\n",
            "loss: 0.392614  [ 3200/ 6189]\n",
            "loss: 0.062450  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.794773 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.034458  [    0/ 6189]\n",
            "loss: 0.081797  [ 1600/ 6189]\n",
            "loss: 0.030575  [ 3200/ 6189]\n",
            "loss: 0.014539  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.507921 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.108945  [    0/ 6189]\n",
            "loss: 0.036193  [ 1600/ 6189]\n",
            "loss: 0.006420  [ 3200/ 6189]\n",
            "loss: 0.019293  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 4.050555 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.017221  [    0/ 6189]\n",
            "loss: 0.038242  [ 1600/ 6189]\n",
            "loss: 0.000466  [ 3200/ 6189]\n",
            "loss: 0.060253  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.685723 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.017790  [    0/ 6189]\n",
            "loss: 0.317504  [ 1600/ 6189]\n",
            "loss: 0.014718  [ 3200/ 6189]\n",
            "loss: 0.245669  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.833365 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.001959  [    0/ 6189]\n",
            "loss: 0.031551  [ 1600/ 6189]\n",
            "loss: 0.261924  [ 3200/ 6189]\n",
            "loss: 0.093204  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.916710 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.259722  [    0/ 6189]\n",
            "loss: 0.036974  [ 1600/ 6189]\n",
            "loss: 0.021042  [ 3200/ 6189]\n",
            "loss: 0.112714  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.688244 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.137984  [    0/ 6189]\n",
            "loss: 0.087292  [ 1600/ 6189]\n",
            "loss: 0.006887  [ 3200/ 6189]\n",
            "loss: 0.331628  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.939213 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.075708  [    0/ 6189]\n",
            "loss: 0.019168  [ 1600/ 6189]\n",
            "loss: 0.004677  [ 3200/ 6189]\n",
            "loss: 0.058421  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 4.002549 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.005280  [    0/ 6189]\n",
            "loss: 0.024194  [ 1600/ 6189]\n",
            "loss: 0.631887  [ 3200/ 6189]\n",
            "loss: 0.029151  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.838400 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.012901  [    0/ 6189]\n",
            "loss: 0.007890  [ 1600/ 6189]\n",
            "loss: 0.295010  [ 3200/ 6189]\n",
            "loss: 0.003221  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 4.089282 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.007146  [    0/ 6189]\n",
            "loss: 0.015803  [ 1600/ 6189]\n",
            "loss: 0.003082  [ 3200/ 6189]\n",
            "loss: 0.058040  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 4.021181 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.099284  [    0/ 6189]\n",
            "loss: 0.013295  [ 1600/ 6189]\n",
            "loss: 0.008320  [ 3200/ 6189]\n",
            "loss: 0.063870  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.953374 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.028350  [    0/ 6189]\n",
            "loss: 0.045547  [ 1600/ 6189]\n",
            "loss: 0.013386  [ 3200/ 6189]\n",
            "loss: 0.007845  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.936762 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.158431  [    0/ 6189]\n",
            "loss: 0.007950  [ 1600/ 6189]\n",
            "loss: 0.004759  [ 3200/ 6189]\n",
            "loss: 0.005088  [ 4800/ 6189]\n",
            "Test Error: \n",
            " F1: 0.4, Avg loss: 3.950613 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dl, model, loss_fn, optimizer)\n",
        "    test_loop(valid_dl, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "IECG_class",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "bbcdeb7d15dcac61ca91bee53812faeef55a0a155c00ab6e46b2ea63ce27864b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
